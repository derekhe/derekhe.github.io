<!DOCTYPE html><html><head><meta name="generator" content="Hexo 3.9.0"><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="baidu-site-verification" content="aZ679hf2Rw"><title> 我是思聪</title><meta name="description" content="A Blog Powered By Hexo"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/favicon.ico"><link rel="stylesheet" href="/css/prontera.css"><link rel="search" type="application/opensearchdescription+xml" href="http://www.april1985.com/atom.xml" title="我是思聪"><!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-129409069-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-129409069-1');
</script>


<script>
  (function(){
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      if (curProtocol === 'https') {
          bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
      }
      else {
          bp.src = 'http://push.zhanzhang.baidu.com/push.js';
      }
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
  })();
  </script></head><body><header class="feature-header"><nav class="component-nav"><ul><div class="logo-container"><a href="/"><h2 class="title">我是思聪</h2></a></div><a href="/" target="_self" class="li component-nav-item"><p>现在</p></a><a href="/archives" target="_self" class="li component-nav-item"><p>曾经</p></a><ul class="shortcut-icons"><a href="https://github.com/derekhe" target="_blank"><img src="/images/github.svg" class="icon"></a><a href="/atom.xml" target="_blank"><img src="/images/rss.svg" class="icon"></a></ul></ul></nav></header><main class="container"><div id="body-container"><div id="post-list" class="left"><div class="home post-list"><div class="post-list-item"><article class="post-block"><h2 class="post-title"><a href="/post/2016-12-09-why-docker-use-up-all-your-disk-space/" class="post-title-link">Why docker use up all your disk space?</a></h2><div class="post-info">Dec 9, 2016</div><div class="post-content"><p>I noticed that the docker containers are using more and more disk spaces on host machine. By looking at the disk usage inside docker container, you will not see any disk usage increase. But the aufs file system is increasing.</p>
<p>I found out that there are two days we can use to clean up the space:</p>
<ol>
<li>Restart docker service</li>
<li>Delete the docker container and add it back again.</li>
</ol>
<p>But these ways need stop your service and we still don’t know the root cause.</p>
<p>After a deep search, I finally found that the log file is eating my disk space and docker will not clean or limit the file size by default. My docker container has plenty of logs output to console, so the log file will keep increasing. If I restarted the docker service or recreate docker container, the log is clean up. Fortunately, docker provide us a <a href="https://docs.docker.com/engine/admin/logging/overview/" target="_blank" rel="noopener">option</a> to limit the log size:</p>
<figure class="highlight vim"><table><tr><td class="code"><pre><span class="line">--<span class="built_in">log</span>-<span class="keyword">opt</span> <span class="built_in">max</span>-size=[<span class="number">0</span>-<span class="number">9</span>]+[kmg]</span><br><span class="line">--<span class="built_in">log</span>-<span class="keyword">opt</span> <span class="built_in">max</span>-<span class="keyword">file</span>=[<span class="number">0</span>-<span class="number">9</span>]+</span><br><span class="line">--<span class="built_in">log</span>-<span class="keyword">opt</span> labels=label1,label2</span><br><span class="line">--<span class="built_in">log</span>-<span class="keyword">opt</span> env=env1,env2</span><br></pre></td></tr></table></figure>

<p>I recreated my container using max-size option to limit the log size to 100M when running docker.</p>
<figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line">docker <span class="builtin-name">run</span> <span class="built_in">..</span><span class="built_in">..</span> --log-opt <span class="attribute">max-size</span>=100M</span><br></pre></td></tr></table></figure>

<p>By doing this, the problem is solved. You can find out more options for log on that page to manage your log.</p>
</div></article></div><div class="post-list-item"><article class="post-block"><h2 class="post-title"><a href="/post/2016-08-24-api-deisgn-best-practices-txt/" class="post-title-link">再看API设计——从黑客的角度</a></h2><div class="post-info">Aug 24, 2016</div><div class="post-content"><p>互联网的高速发展以及多终端设备的广泛使用使得前后端分离架构变成了必须，越来越多的网络应用暴露出API以便于前端的使用，RESTFul API的设计成为了业界主流的设计范式。在持续的业务增长以及后端技术的革新中，微服务架构(Microservice)崭露头角，解决了单体应用(Monolithic Application)的诸多问题而越来越流行。现在，在客户端与服务、服务与服务之间，有更多的数据通过常用的json等结构化的方式进行交互。这些交互过程在单体应用中对外并不可见，但在微服务架构下对于却变得透明，黑客可以通过窥探及猜测系统内部的结构，会比以前更容易攻击系统。在这篇文章中，我将以一个数据黑客的角度，展示如何利用API来大规模的获取所要的信息。</p>
<h2 id="数据黑客"><a href="#数据黑客" class="headerlink" title="数据黑客"></a>数据黑客</h2><p>数据黑客没有一个准确的定义，在我看来这帮人对于数据具有敏锐的嗅觉；他们尝试得到一切能够获得的数据并进行数据分析；他们尝试在数据的云海中找出规律以便预测未来。在程序员拯救世界的今天，数据黑客则掌握了世界的未来。</p>
<p>在若干年前，前后端分离的架构还尚未普及，很多数据的呈现方式都是直接在页面中打印出来，为了解析数据，数据黑客们使用XPATH去解析数据，将数据装入数据库进行分析，甚至从中赚钱。如今，我们有着大量的API供使用，数据变得唾手可得。我们不用再去繁琐的解析易变的HTML，只需要访问一个URL即可获得我们需要的数据。</p>
<h3 id="10天内获得自由职业网站8百万项目数据"><a href="#10天内获得自由职业网站8百万项目数据" class="headerlink" title="10天内获得自由职业网站8百万项目数据"></a>10天内获得自由职业网站8百万项目数据</h3><p>我对自由职业充满了好奇，想试一下自由职业是怎么接到活的。在Freelancer网站上，几乎每分钟都有新的项目发布，一般一分钟之内就有好几个投标信息(bid)。每个投标信息包含了投标的内容、价格以及完成时间，然后雇主根据这些信息来筛选谁可能接这个项目。一般来讲会在交谈之后，明确所有的事宜后，再将项目分配给自由职业者。</p>
<p>作为自由职业者，我们可以看到其他人投标的价格以及别人的信誉度、别人做过的项目等信息，但不能看到具体的投标内容。作为雇主，价格、自由职业者的信誉度、是否通过一些测试可能都是影响雇主是否第一轮筛选进行交谈。那么，通过数据分析，能否回答以下几个问题以便帮助我们正确的投标：</p>
<ul>
<li>针对投标信息，雇主对自由职业者的信誉度和价格，哪个看得更重？</li>
<li>针对澳洲的雇主，我如何能够增加我被选中的几率，是通过降低价格还是提升自己的质量？</li>
</ul>
<p>为了回答这些问题，我需要尽快的将网站上所有可能拿到的信息都拿下来进行分析。</p>
<h4 id="网站及API分析"><a href="#网站及API分析" class="headerlink" title="网站及API分析"></a>网站及API分析</h4><p>打开一个项目<a href="https://www.freelancer.com/projects/Javascript/Web-Page-Scraper/" target="_blank" rel="noopener">页面(注：你需要翻墙)</a>，你会看到页面如图所示：</p>
<p><img src="/images/2016/8/1.png" alt="image"></p>
<p>简单的看一下HTML后，发现网站将所有的信息都内嵌到HTML中的一个script中，在浏览器执行完成后会得到project变量。这个变量包含了项目的所有信息，所以理论上讲，我们拿到一个HTML然后解析Javascript，是可以得到我们需要的数据的。</p>
<p><img src="/images/2016/8/2.png" alt="image"></p>
<p>但这种方式也存在一些问题，一来是解析HTML非常费事，二来是执行Javascript也比较繁琐。并且没有一个办法能够遍历所有的项目，可行性并不大。</p>
<p>通常来讲，我不会去解析主网站，因为其防范一般比较严。但很多网站的马奇诺防线在移动端就失效了，Freelancer也不例外。</p>
<p>打开<a href="https://m.freelancer.com/projects/Javascript/Web-Page-Scraper/#info" target="_blank" rel="noopener">移动端的网页</a>。简单看一下可以知道它是基于AngularJS写的网站。</p>
<p><img src="/images/2016/8/3.png" alt="image"></p>
<p>通过分析API的请求，可以很快的看到API的样子：</p>
<p><img src="/images/2016/8/4.png" alt="image"></p>
<p>我们来分析一下这个URL，红色部分代表了这个项目的简写名字，将其改为其他的项目名称以后能够得到对应的信息。</p>
<p><img src="/images/2016/8/5.png" alt="image"></p>
<p>理论上我只要得到所有项目的简写名字，再用这个地址就可以获得所有的信息了。但且慢，我注意到了投标信息的API：</p>
<p><img src="/images/2016/8/7.png" alt="image"></p>
<p>红色部分用的是一串数字，如果你了解RESTFul API，则很容易知道这个bids的信息是属于9844976项目的。将之前的projects后面的名字变为数字，果然返回ID为9844976的项目的信息，和用简写名字同样的效果。这样的话我就确定了网站每个项目的ID是可以直接访问的，从0开始遍历这个ID即可得到所有网站的信息。</p>
<p><img src="/images/2016/8/8.png" alt="image"></p>
<h4 id="阻力：API访问速度限制"><a href="#阻力：API访问速度限制" class="headerlink" title="阻力：API访问速度限制"></a>阻力：API访问速度限制</h4><p>当爬到1000个左右的时候，网站就报告API Rate Limit限制了，大概需要一个小时左右才能再次访问。作为一个大型的网站，API访问速度限制是很平常的事情。如果照这个速度访问，则爬完所有的信息需要将近一年。能不能更快呢？</p>
<p>通过匿名代理可以让访问的服务器无法识别出您的真实的IP地址，所以如果有大量的匿名代理，就可以满足爬虫的需求。但这个网站使用的是HTTPS，要找到大量稳定的HTTPS代理需要较高的代价，网络上常见的匿名代理网站提供的代理通常都不稳定。</p>
<p><img src="/images/2016/8/10.png" alt="image"></p>
<p>那么，有没有一个更廉价的方式能够获得更多的IP地址呢？洋葱网络为我们提供可以非常好的途径来隐藏自己的真实身份，并能够得到大量稳定的IP，并且能够在达到API Rate Limit之前就更新IP地址，非常符合我们的要求。</p>
<p><img src="/images/2016/8/11.png" alt="image"></p>
<p>为了让多线程并行，我在<a href="https://m.do.co/c/4bc532e3ef94" target="_blank" rel="noopener">DigitalOcean的5美元的服务器</a>上用Docker启动了10个Tor的客户端，这样每个客户端就拥有一个独立的IP，并且每10秒钟切换一次。脚本连续运行10天后，所有的数据全部到达本地。</p>
<h4 id="从黑客的角度看"><a href="#从黑客的角度看" class="headerlink" title="从黑客的角度看"></a>从黑客的角度看</h4><p>好的几点：</p>
<ul>
<li>该网站提供了移动端的API。</li>
<li>有API的限速。</li>
</ul>
<p>需要改进的有：</p>
<ul>
<li>ID号可遍历：通过将ID变为UUID，可以解决资源被遍历的问题。但这个要视业务场景来定，如果业务上并没有需要保护数据，则简单的ID也是一种选择。</li>
<li>加载的数据包含了很多额外的信息，造成一些信息泄露：在返回的数据中包含了大量的其他信息，黑客可以利用此信息得到页面上没有显示的信息。例如网站上对投标者对雇主的id、用户名等信息是不知道的，但API返回的数据中却有这些信息。这样黑客可以通过这些信息通过其他渠道联系上雇主。</li>
<li>保护网站遭受匿名网络攻击：根据业务的不同，可以设置针对地域的IP限制。例如如果网站大部分针对澳洲客户，则澳洲客户的API使用量可以设置为1千/小时，而其他国家则设置为100个/小时，并且在适当时候显示验证码。</li>
</ul>
<p><img src="/images/2016/8/12.png" alt="image"></p>
<h3 id="获得一年中6亿的机票数据"><a href="#获得一年中6亿的机票数据" class="headerlink" title="获得一年中6亿的机票数据"></a>获得一年中6亿的机票数据</h3><p>由于家庭的需要，我会在节假日往返成都和广州，而我想买到最便宜的机票。那么问题在于，我需要提前多少天才能买到足够便宜的机票呢？在我得到数据之前，我曾手工的看机票的数据，但很难发现规律，往往意识到涨价的时候，已经比最低值高出了很多。如果我能持续的抓取每天看到的30天之内的机票的数据，并用于一年后的数据分析，我是否能够找到一些规律呢？</p>
<p>为了完成这个任务，从2012年开始，我开始从各大机票售卖网站抓取机票信息。这里想举一个从某网站中获取机票的例子来看看我们能够从中学到一些什么。</p>
<p>我之前说过从主站入手往往很难攻破，所以直接打开移动的网站：</p>
<p><img src="/images/2016/8/13.png" alt="image"></p>
<p>只需要看一下网络的请求就可以很方便的定位到获取机票的API以及返回值：</p>
<p><img src="/images/2016/8/14.png" alt="image"></p>
<h4 id="API分析"><a href="#API分析" class="headerlink" title="API分析"></a>API分析</h4><p>来我们看看API中包含了些什么：</p>
<figure class="highlight gcode"><table><tr><td class="code"><pre><span class="line">data=<span class="meta">%</span><span class="number">7</span>B<span class="meta">%</span><span class="number">22</span>searchType<span class="meta">%</span><span class="number">22</span><span class="meta">%</span><span class="number">3</span>A<span class="meta">%</span>……</span><br></pre></td></tr></table></figure>

<p>这部分应该是存储的数据，很简单，我们通过decodeURI即可得到可见的信息：</p>
<p><img src="/images/2016/8/15.png" alt="image"></p>
<p>后面一部分是固定的串，有API的key以及版本信息</p>
<figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="attr">useNative</span>=<span class="literal">true</span>&amp;ttid=<span class="number">201300</span>@travel_h<span class="number">5_3</span>.<span class="number">1.0</span>&amp;appKey=<span class="number">12574478</span></span><br></pre></td></tr></table></figure>

<p>对于爬虫来讲，最麻烦的部分在于：</p>
<figure class="highlight excel"><table><tr><td class="code"><pre><span class="line"><span class="built_in">t</span>=<span class="number">1426062775998</span>&amp;<span class="built_in">sign</span>=<span class="number">3</span>feb52aed67967a2c47aa7a2b9f2a417</span><br></pre></td></tr></table></figure>

<p><img src="/images/2016/8/16.png" alt="image"></p>
<p>这部分一直在变，并且若干秒后会失效。sign的计算和cookie中的<em>m</em>h5_tk有很大的关系，并且每次服务器要返回新的<em>m</em>h5_tk的token用于下一次请求。所以如果要生成这个url，必须要将他的计算规律搞清楚。对手前端的加密来讲，基本上如果了解js的开发，能够较快的找出来。首先搜索API中包含的字符串h5apiUpdate，很容易就定位到这里：</p>
<p><img src="/images/2016/8/17.png" alt="image"></p>
<p>但这部分代码已经被压缩，无法打断点。Chrome提供了一个非常棒的代码格式化工具可以方便的将代码格式化为可读性很好的代码：</p>
<p><img src="/images/2016/8/18.png" alt="image"><br><img src="/images/2016/8/19.png" alt="image"></p>
<p>再在这里打上断点，所有的秘密都呈现在了眼前：</p>
<p><img src="/images/2016/8/20.png" alt="image"><br><img src="/images/2016/8/21.png" alt="image"></p>
<p>剩下的事情就是将这个写成脚本即可，请参考后记。</p>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>从这个例子中我们学到了什么：</p>
<ul>
<li>可以用时间作为token来生成动态的url</li>
<li>用sign去检查请求是否合法</li>
<li>服务端可以用时间token来拒绝重发的请求</li>
<li>JS端的压缩可以较为容易的破解</li>
</ul>
<h1 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h1><p>以上的代码我都分享在我的<a href="https://github.com/derekhe/" target="_blank" rel="noopener">github账号</a>。仅用于学习用途，请勿用于恶意攻击。</p>
<ul>
<li>关于爬Freelancer那的<a href="https://github.com/derekhe/freelancer-crawler" target="_blank" rel="noopener">代码</a>。</li>
<li>机票爬取的部分<a href="https://github.com/derekhe/alitripAPI" target="_blank" rel="noopener">代码</a>。由于网站已经升级，反爬措施变得比较难于琢磨，所以这段代码已经无法正常运行了，仅供参考。</li>
<li>还有1分钟启动10个tor的<a href="https://github.com/derekhe/tor-client-minimal" target="_blank" rel="noopener">代码</a>。</li>
</ul>
<p>后来我发现Freelancer网站有一个隐藏的<a href="https://www.freelancer.com/api/docs/" target="_blank" rel="noopener">API接口文档</a>，在这个文档中还有更多的信息可以参考。另外知乎上也有一些反爬虫的一些讨论，挺有趣，可以<a href="https://www.zhihu.com/question/28168585" target="_blank" rel="noopener">参考</a>。</p>
</div></article></div><div class="post-list-item"><article class="post-block"><h2 class="post-title"><a href="/post/2016-04-05-api-deisgn-best-practices/" class="post-title-link">API Design Best Practices -- From a hacker's view</a></h2><div class="post-info">Apr 5, 2016</div><div class="post-content"><p>两个星期前接到一个大坑，成都办公室需要人去参加客户的一个API的活动。和几个同事头脑风暴一番以后，发现客户已经有我们需要讲的议题了。那么我们搞点特别的吧，他们讲一些小正面的，我面来一些反面的。然后我就跳到了这个坑里。</p>
<p>从准备材料到最终讲只剩下一个多星期，花了两天多准备PPT，板式采用纯黑的主题，加上一些在flaticon上面找的图标，配起来自我感觉良好^_^。PPT在分享在<a href="http://www.slideshare.net/hesicong/api-design-best-practices-from-a-hackers-view" target="_blank" rel="noopener">这里</a>，有兴趣的可以看。</p>
<p>关于Freelancer那的<a href="https://github.com/derekhe/freelancer-crawler" target="_blank" rel="noopener">代码</a>，阿里那一段段的<a href="https://github.com/derekhe/alitripAPI" target="_blank" rel="noopener">代码</a>，还有1分钟启动10个tor的<a href="https://github.com/derekhe/tor-client-minimal" target="_blank" rel="noopener">代码</a>。</p>
<p>其实最近我发现Freelancer也是提供了API的文档的，只是这个网站的页面设计得很奇葩，找东西非常难找，在<a href="https://www.freelancer.com/api/docs/" target="_blank" rel="noopener">这里</a>。</p>
</div></article></div><div class="post-list-item"><article class="post-block"><h2 class="post-title"><a href="/post/2015-12-21-emei-mountain-2/" class="post-title-link">乐山峨眉游（2）</a></h2><div class="post-info">Dec 21, 2015</div><div class="post-content"><p>第二天早上不慌不慢，快要10点钟过去游客中心买票上车，淡季110+90车费。票价默认给你加5块钱，我明确说不要保险，就省了10块钱保险费，真的没啥必要。从游客中心到零公里坐车要一个多小时，还好自己没开车。</p>
<p>到达零公里的时候就要换车了，由于一些人是没有买门票的所以在这里需要补票。还好我们是买了票的，检票的有两个地方，运气比较好的是第二条线没有排多长，抱着儿子赶紧跑过去，抢了个前面的地方。检票几分钟就过了，换另外个大巴车上车。中途有一个小插曲，一个拿本地身份证的人在检票口过不去，因为人对不上号，被要求重新补票。在山脚下就有很多人兜售这样的票，如果不是本地身份证这里就傻了。</p>
<a id="more"></a>

<p>冬季由于山上积雪，车只能停到零公里。旅游车刚上去一点路，就开始挂雪地链了。一路又花费一个小时，到了雷洞坪，已经12点了。</p>
<p>下车给小孩拉个尿，在<a href="http://www.dianping.com/shop/19717114" target="_blank" rel="noopener">全福商务酒店</a>休息一下。本来背了两盒自热米饭，准备山顶吃的，但老婆觉得该吃饭了，那就吃吧。现在的旅游比之前规范了很多，什么东西都是明码标价，而且分量也是标准的，看来之前肯定是坑了很多人然后政府出来规范的。点了两个菜，都不错，分量确实也不错，三个人吃了42块钱。老板和我们一桌吃饭，他说今天天气好，上面有太阳，哇塞！我们又再问现在滑雪还来得及不，他说不行。上了金顶就没时间了。而且滑雪一个小时的免费，等弄好器具都20分钟了，再滑一下就一两个小时过去了，然后就收钱了，哈哈。老板真实在。</p>
<p>在雪地上一定要冰爪，否则滑你没商量。上次在海螺沟就幸好买了几个便宜的，要不然根本没法走。后来老爸做了好几个简易的，这次又派上用场了。</p>
<p>从雷洞坪到金顶缆车还有一段路程（地图上显示1.1公里），在冰雪上面带着小孩走了接近一个小时，一路上吵着要买铲子。还好丁仔比较坚强，一路到头。路上的猴子还好啦，没有生态猴区那么猛，很温顺。</p>
<p><img src="/images/2015/12/IMG_0241.jpg" alt="猴子必不可少"><br><img src="/images/2015/12/IMG_0245.jpg" alt="猴子必不可少"><br><img src="/images/2015/12/IMG_0250.jpg" alt="猴子必不可少"></p>
<p>出太阳啦！！！<br><img src="/images/2015/12/IMG_0248.jpg" alt="出太阳啦"></p>
<p>坐到缆车已经是两点钟了，时间过得真快。我们坐的不是那个很大的缆车，好像冬天没有开。缆车风景非常漂亮，只是缆车速度很快，有些接头的地方抖一抖吓死人。</p>
<p><img src="/images/2015/12/IMG_0253.jpg" alt><br><img src="/images/2015/12/IMG_0256.jpg" alt><br><img src="/images/2015/12/IMG_0257.jpg" alt><br><img src="/images/2015/12/IMG_0258.jpg" alt><br><img src="/images/2015/12/IMG_0262.jpg" alt></p>
<p>小朋友上山以后就有点走不动了，原来是脚趾头受伤了。一路上试着抱着背着，好累。来，做几个雪球。</p>
<p><img src="/images/2015/12/IMG_0274.jpg" alt><br><img src="/images/2015/12/IMG_0283.jpg" alt></p>
<p>这次运气真的很好，金顶上阳光很足，云海非常漂亮。除了坐飞机，这是第一次看到这么漂亮的云海。可以看到远处的瓦屋山，甚至更远的贡嘎山。</p>
<p><img src="/images/2015/12/IMG_0287.jpg" alt><br><img src="/images/2015/12/IMG_0288.jpg" alt></p>
<p>全景：<br><img src="/images/2015/12/IMG_0291.jpg" alt><br><img src="/images/2015/12/IMG_0292.jpg" alt><br><img src="/images/2015/12/IMG_0293.jpg" alt><br><img src="/images/2015/12/IMG_0294.jpg" alt><br><img src="/images/2015/12/IMG_0295.jpg" alt></p>
<p>猜猜这是什么山？<br><img src="/images/2015/12/IMG_0301.jpg" alt></p>
<p>有两个平顶的山，这个的是瓦屋山<br><img src="/images/2015/12/IMG_0311.jpg" alt></p>
<p>这个是什么山呢？</p>
<p><img src="/images/2015/12/IMG_0318.jpg" alt></p>
<p>问问[度娘]（<a href="http://tieba.baidu.com/p/833837251）" target="_blank" rel="noopener">http://tieba.baidu.com/p/833837251）</a></p>
<p>一路上小朋友都想要铲雪的铲子，想了好久，路上问了小卖部没得卖。好吧，只能打劫一个了。遇到了一个美女背一个小孩，看起来也是背个铲子多事的，给了25块钱买了个铲子。这下丁仔满意了，一路上当铲雪工，非常高兴。</p>
<p><img src="/images/2015/12/IMG_0325.jpg" alt></p>
<p>阳光下的金顶非常漂亮，但是小朋友有点害怕。十年前和朋友夏天来这里的时候，全是雾气，一点都不壮观。这次非常的通透，当然上面的雪也已经比较硬了，风也非常大，冷风就像刀割一样。</p>
<p><img src="/images/2015/12/IMG_0319.jpg" alt><br><img src="/images/2015/12/IMG_0330.jpg" alt></p>
<p>勤劳的铲雪工<br><img src="/images/2015/12/IMG_0339.jpg" alt></p>
<p>月亮都能看到啦<br><img src="/images/2015/12/IMG_0342.jpg" alt></p>
<p>刚好挡着太阳，感觉像是发光一样<br><img src="/images/2015/12/IMG_0345.jpg" alt><br><img src="/images/2015/12/IMG_0346.jpg" alt><br><img src="/images/2015/12/IMG_0347.jpg" alt><br><img src="/images/2015/12/IMG_0348.jpg" alt><br><img src="/images/2015/12/IMG_0349.jpg" alt></p>
<p>3点50左右，赶紧下山，因为观光车5点钟就要收车了。一路上背着丁丁赶路下去，坐缆车，继续赶路，最后4点40多到车站。仔仔已经冷的双手发冷，玩了一个雪球以后看起来没精神了，抱在怀里睡了一觉。之前都是老婆抱的，这次我来抱，足足站了半个多小时，终于上了车。今天由于有一些活动，搞得观光车有点接不上气，排队排的很远，还好我们下去的稍微早点，要不然更惨。</p>
<p>一坐上车小宝就醒了，一路上精神得很。一路上我都试着睡觉，但山路甩得我都晕晕的想吐，只有不睡，看着路，很难受。这个状态是没法回成都了。下山到客运中心已经是7点过了，还是决定就住下吧。吃了个<a href="http://www.dianping.com/shop/19106338" target="_blank" rel="noopener">3077烧烤麻辣烫排档</a>，不怎么好吃，拿上来就冷了，又辣得要死，没啥特色。给小孩点的蛋炒饭还行。</p>
<p>晚上住在<a href="http://hotels.ctrip.com/hotel/1562112.html#ctm_ref=hod_sr_lst_dl_n_1_1" target="_blank" rel="noopener">橡树缘连锁</a>地中海主题，也是直接过去订房，由于是周日了，所以价格也便宜150住一晚。房间装修还算比较有风格，但空调也是响，由于不是变频空调，突然制热响一下吓一跳。其他东西还算可以吧，卫浴都是TOTO的，但不知道为啥烧水一直有一股烧糊的怪味，很奇怪。没注意到上一家酒店也是不是这样。这个亲子房有一个1.5米的床，有一个1.2米的。我睡1.2米的被子，但被子短了，郁闷。</p>
<p>睡好觉，周一回成都，在乐山买了<a href="http://www.dianping.com/shop/5383680" target="_blank" rel="noopener">王浩儿纪六孃(致江路总店)</a>买了鸭子，在<a href="http://www.dianping.com/shop/27272047" target="_blank" rel="noopener">乡村黑豆花佛光路店</a>吃了中午饭，很棒，然后就回成都了。</p>
<p>累死哥哥了。。。。</p>
</div></article></div><div class="post-list-item"><article class="post-block"><h2 class="post-title"><a href="/post/2015-12-21-emei-mountain-1/" class="post-title-link">乐山峨眉游（1）</a></h2><div class="post-info">Dec 21, 2015</div><div class="post-content"><p>峨眉山半价，走起！我从来都是不打不准备的仗，周五发红包给公司群，同事推荐了好多地方，花点钱真心不错。周六早上出发开车到乐山，中午就到乐山。下了高速赶紧定位到古市香跷脚牛肉，大众点评上有个订座的功能，开车半个小时到地方。</p>
<p>不得不说这个地方真的很火，在一条小巷子里面，有点不方便开车。在河边有免费停车的地方，，还算比较方便。下了车到店，发现这个不是一般的热闹，排号都排了很长。还好我是大众点评上先预定了的，马上安排座位，等了大概10分钟，还算幸福的啦。</p>
<a id="more"></a>

<p>牛杂牛肉粉蒸牛肉，依次点起！</p>
<p><img src="/images/2015/12/IMG_0151.jpg" alt><br><img src="/images/2015/12/IMG_0152.jpg" alt><br><img src="/images/2015/12/IMG_0154.jpg" alt><br><img src="/images/2015/12/IMG_0156.jpg" alt></p>
<p>房顶也有特色</p>
<p><img src="/images/2015/12/IMG_0159.jpg" alt><br><img src="/images/2015/12/IMG_0160.jpg" alt></p>
<p>外面卖的泡菜，要钱的哟，没点<br><img src="/images/2015/12/IMG_0164.jpg" alt><br><img src="/images/2015/12/IMG_0171.jpg" alt></p>
<p>吃好了一顿，也就100多块钱，非常的爽。牛杂我只吃牛肚，但牛肉吃了很多，粉蒸肉也吃完了，哈哈。</p>
<p>下午决定还是去乐山大佛一趟，去峨眉爬山时间肯定是不够了。车停在乐山大佛景区门口的景园停车场，20块钱的停车费，要了发票（这是我的特点，一定要发票），居然是那种餐饮样式的发票，盖章倒是正规的，还有刮奖。我的运气还算不错，一 5块，嘿嘿。</p>
<p>乐山大佛我倒是很小的时候去过，已经没有记忆了，只有照片。现在自己有了儿子，带着儿子重温我小时候的记忆。</p>
<p><img src="/images/2015/12/IMG_0181.jpg" alt="乐山大佛"></p>
<p>小朋友还是挺厉害的，自己爬山到顶上。下栈道就有点郁闷了，第一个转弯就堵了，半天不动。想想这还是个普通的周末，要是黄金周我看怎么办。走到一半才发现，台阶太陡，路越来越窄，只有够一个人，老婆提着儿子往下走，真的有点艰难。</p>
<p><img src="/images/2015/12/IMG_0215.jpg" alt="乐山大佛"><br><img src="/images/2015/12/IMG_0221.jpg" alt="乐山大佛"><br><img src="/images/2015/12/IMG_0223.jpg" alt="下山栈道"><br><img src="/images/2015/12/IMG_0225.jpg" alt="乐山大佛"></p>
<p>下山以后去峨眉山了，天色有点晚，还没订酒店。酒店的问题真是让我头痛，以前遭过两次，订了酒店没法取消，小孩生病没法去，白白的损失了一千多。这算是峨眉山旅游淡季了，应该没有那么挤。到了峨眉山脚下再找酒店，发现很多酒店都没了。也没关系，一家一家的打电话，最后找到了<a href="http://hotels.ctrip.com/hotel/447011.html#ctm_ref=www_hp_bs_lst" target="_blank" rel="noopener">“凤缘酒店”</a>还有房间。</p>
<p>老婆上去看了下房间，找了一间还不错的。讲价128一晚，携程上面订的的话要168的。停车还算不错了，虽然酒店门口只有三个位置，但后面一条巷子还有很大的停车场。老板一起带过去，免费停。房屋临街，但隔音做的不错不吵。房间有一点霉味，其他都还算好了。空调也不错，只是晚上有一些噪音，后来索性关了空调。</p>
<p>在老板娘那里订了灵秀温泉的票，网上买138，这里买125。后来才知道我们的价格也有点贵了，在外面有一个小超市门口有一个牌牌写的110-125，110块钱其实也能买到。晚上随便在外面找个了餐厅，结果找了个巨难吃的地方，详见<a href="http://www.dianping.com/shop/44082643" target="_blank" rel="noopener">我的点评</a>：</p>
<blockquote>
<p>在这里吃过，价格比较贵不说，还做的相当难吃。<br>凤尾炒的全是烂七八糟的，酸菜粉丝汤的粉丝也是一股怪味，甚至酸菜里面还有一些清凉油的味道。最奇葩的苦笋，一股清凉油的味道，老板还是绝对是对的，也是醉了。。。，再也别去这里了</p>
</blockquote>
<p>晚上去泡温泉，温泉距离酒店还是有一点距离，走路10分钟。大冬天的好冷啊。换了票进去，每个人要把鞋子脱了给你一个号。原来是因为后续你可以用这个号开关门，然后还可以买东西，最后出来的时候拿鞋子给钱。换衣服的地方还不是很冷，要主动去要浴袍，一个人只能拿一次干的。</p>
<p>温泉还是可以的，小孩的游泳圈没有带，有点郁闷。在外面的温泉玩了一下，赶紧到室内的温泉。室内的就要好很多了，泡了一个多小时，没有太大的感觉，回去赶紧再冲个热水澡。。。。</p>
<p>晚上睡了个好觉，准备第二天爬山。</p>
</div></article></div></div></div><div id="sidebar" class="left"><div id="about-panel"><div class="info"><div class="title">贺思聪</div><div class="bio">《爬虫实战：从数据到产品》作者，国内首个机票价格历史及预测小程序“爱飞狗旅行”作者，极客、架构师、大数据玩家。</div></div><img src="/images/avatar.png" class="avatar"></div><div id="friend-links-panel"><div class="panel-title"><p>LINKS</p></div><a href="http://github.com/derekhe" target="_blank" class="link-item"><div class="link-container"><div class="site-name">GitHub</div><div class="site-desc">http://github.com/derekhe</div></div></a><a href="http://www.jianshu.com/u/b1e713e56ea6" target="_blank" class="link-item"><div class="link-container"><div class="site-name">简书</div><div class="site-desc">http://www.jianshu.com/u/b1e713e56ea6</div></div></a><a href="https://www.linkedin.com/in/sicong-he-56a95437/" target="_blank" class="link-item"><div class="link-container"><div class="site-name">LinkedIn</div><div class="site-desc">https://www.linkedin.com/in/sicong-he-56a95437/</div></div></a></div></div></div><div class="clear"></div></main><footer class="footer-container"><div class="paginator"><a href="/page/4/" class="prev">PREV</a><a href="/page/6/" class="next">NEXT</a></div><div class="copyright"><p>© 2008 - 2020 <a href="http://www.april1985.com">贺思聪</a>, powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/AngryPowman/hexo-theme-prontera" target="_blank">hexo-theme-prontera</a>.</p></div></footer><script>var _mtac = {}; (function() {     var mta = document.createElement("script"); mta.src = "http://pingjs.qq.com/h5/stats.js?v2.0.2";    mta.setAttribute("name", "MTAH5");    mta.setAttribute("sid", "500490740");    var s = document.getElementsByTagName("script")[0];    s.parentNode.insertBefore(mta, s);})();</script></body></html>